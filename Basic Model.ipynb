{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n",
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import extract_faces_keep_in_mem\n",
    "from search_videos_in_directory import search_videos\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the absolute path of the input directory: /home/debanik/downloaded_videos\n",
      "Enter the absolute path of the output directory: /home/debanik/PycharmProjects/Detecting-Deepfakes/Face_images\n",
      "Enter the number of images to be generated per video file: 1\n"
     ]
    }
   ],
   "source": [
    "input_direc = input(\"Enter the absolute path of the input directory: \")\n",
    "output_direc = input(\"Enter the absolute path of the output directory: \")\n",
    "try:\n",
    "    os.mkdir(output_direc)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "search_videos(input_direc, output_direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(output_direc):\n",
    "    for file in files:\n",
    "\n",
    "        try:\n",
    "            im = Image.open(root + '/' + str(file))\n",
    "            im.verify()\n",
    "        except:\n",
    "            print(str(file))\n",
    "            os.remove(root + '/' + str(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_direc = '/home/debanik/downloaded_videos'\n",
    "# output_direc = '/home/debanik/PycharmProjects/Detecting-Deepfakes/Face_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generator\n",
    "datagen = ImageDataGenerator(samplewise_center=True, \n",
    "                             samplewise_std_normalization=True, \n",
    "                             rotation_range=10, \n",
    "                             horizontal_flip = True, \n",
    "                             validation_split=0.2)\n",
    "# prepare an iterators for each dataset\n",
    "train_it = datagen.flow_from_directory(output_direc, class_mode='binary', batch_size=64)\n",
    "# # confirm the iterator works\n",
    "# batchX, batchy = train_it.next()\n",
    "# print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape = (256, 256, 3))\n",
    "\n",
    "x1 = Conv2D(16, (3, 3), strides = 1, padding='same', activation = 'relu')(x)\n",
    "x1 = Conv2D(4, (1, 1), padding='same', activation = 'relu')(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(8, 8), padding='same')(x1)\n",
    "\n",
    "y = Flatten()(x1)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Dense(1, activation = 'sigmoid')(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = x, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.fit_generator(train_it, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
